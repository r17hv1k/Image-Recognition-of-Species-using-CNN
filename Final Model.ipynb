{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"g1zQMCZb1GOT"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from keras.layers import Dropout, Dense, GlobalAveragePooling2D\n","from keras.applications.inception_v3 import InceptionV3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ9IlXmQ1KtH"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3IXerYI1GOW"},"outputs":[],"source":["batch_size=64\n","data_dir = \"/Project/data/animals\"\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","        validation_split=0.2,\n","        rotation_range=35,\n","        width_shift_range=0.25,\n","        preprocessing_function=tf.keras.applications.resnet.preprocess_input,\n","        height_shift_range=0.25,\n","        shear_range=0.25,\n","        zoom_range=0.25,\n","        horizontal_flip=True,\n","        fill_mode='nearest')\n","validation_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0.2)\n","\n","\n","train_generator = train_datagen.flow_from_directory(data_dir,\n","    target_size=(299,299),\n","    class_mode='categorical',\n","    batch_size=batch_size,\n","    subset = \"training\")\n","validation_generator = validation_datagen.flow_from_directory(data_dir,\n","    target_size=(299,299),\n","    class_mode='categorical',\n","    batch_size=batch_size,\n","    subset = \"validation\")\n","\n","labels = {v: k for k, v in train_generator.class_indices.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxzJNxps1GOY"},"outputs":[],"source":["pre_trained_model = InceptionV3(input_shape=(299, 299, 3), include_top=True, weights='imagenet')\n","\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","\n","last_output = pre_trained_model.get_layer('mixed10').output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FJRp7Gq1GOZ"},"outputs":[],"source":["x = layers.Dense(1024, activation='relu')(last_output)\n","x = layers.Dropout(0.2)(x)\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(90, activation='softmax')(x)\n","model = Model(pre_trained_model.input, x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGJfBM5C1GOa"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehfMY2lS1GOa"},"outputs":[],"source":["model.compile(optimizer='rmsprop',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHX7J9kD1GOb"},"outputs":[],"source":["load_model = True\n","if load_model:\n","    model = keras.models.load_model('/Project/FinalModel.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCGy3Yd81GOb"},"outputs":[],"source":["if not load_model:\n","    history = model.fit(train_generator,\n","                        validation_data=validation_generator,\n","                        epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPKtepO21GOc"},"outputs":[],"source":["model.evaluate(validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUUtYEEr1GOd"},"outputs":[],"source":["#model.save('FinalModel.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76rfZdyc1GOd"},"outputs":[],"source":["testing_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0)\n","testing_data = testing_datagen.flow_from_directory('/Project/testing_images',\n","     target_size=(299,299),\n","    class_mode=None,\n","    batch_size=1,\n","    subset=\"training\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkKBz4_U1GOe","scrolled":true},"outputs":[],"source":["np.argmax(model.predict(testing_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Y_1laYb1GOf"},"outputs":[],"source":["labels[np.argmax(model.predict(testing_data))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zevLd-H0hWkh"},"outputs":[],"source":["pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yNKLerpo677L"},"outputs":[],"source":["import gradio as gr\n","from google.colab import drive\n","from PIL import Image\n","import shutil\n","import io\n","\n","# drive.mount('/content/gdrive')\n","\n","def upload_image(image):\n","    pil_image = Image.fromarray(image)\n","\n","    image_path = '/Project/testing_images/images/uploaded_image.jpg'\n","    pil_image.save(image_path)\n","    testing_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0)\n","    testing_data = testing_datagen.flow_from_directory('/Project/testing_images',\n","    target_size=(299,299),\n","    class_mode=None,\n","    batch_size=1,\n","    subset=\"training\")\n","    output=labels[np.argmax(model.predict(testing_data))]\n","    return output\n","\n","image_upload = gr.inputs.Image()\n","\n","text_output = gr.Textbox(label=\"Output\")\n","\n","interface = gr.Interface(fn=upload_image, inputs=image_upload, outputs=text_output, title='Image Uploader')\n","\n","interface.launch(debug=True)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
